===========================================================================
General:
===========================================================================

@misc{handbook,
	title={Recommender Systems Handbook.},
	author={Shapira, Bracha and Ricci, Francesco and Kantor, Paul B and Rokach, Lior},
	year={2011},
	publisher={Springer}
}
Handbook

@inbook{dataMining,
	booktitle={Data Mining: Concepts and Techniques},
	title={Getting to Know Your Data},
	chapter={2},
	author={Han, Jiawei and Pei, Jian and Kamber, Micheline},
	year={2011},
	publisher={Elsevier}
}
Data Mining book


@inproceedings{netflixPrize,
	title={The netflix prize},
	author={Bennett, James and Lanning, Stan},
	booktitle={Proceedings of KDD cup and workshop},
	volume={2007},
	pages={35},
	year={2007}
}
Netflix prize assignment and dataset description

===========================================================================
Collaborative filtering - Memory-based
===========================================================================

@article{amazonItemItem,
  title={Amazon. com recommendations: Item-to-item collaborative filtering},
  author={Linden, Greg and Smith, Brent and York, Jeremy},
  journal={IEEE Internet computing},
  volume={7},
  number={1},
  pages={76--80},
  year={2003},
  publisher={IEEE}
}
Amazons item-item approach (should be similar to mine)


@inproceedings{itemItemAlgorithms,
	title={Item-based collaborative filtering recommendation algorithms},
	author={Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John},
	booktitle={Proceedings of the 10th international conference on World Wide Web},
	pages={285--295},
	year={2001},
	organization={ACM}
}
For rating, with correlation and cosine similaritiy, compared to user-user

@inproceedings{efficientTopN,
	title={Efficient top-n recommendation for very large scale binary rated datasets},
	author={Aiolli, Fabio},
	booktitle={Proceedings of the 7th ACM conference on Recommender systems},
	pages={273--280},
	year={2013},
	organization={ACM}
}
item-item and user-user approaches with improvements


@inproceedings{effectiveLatentModels,
	title={Effective Latent Models for Binary Feedback in Recommender Systems},
	author={Volkovs, Maksims and Yu, Guang Wei},
	booktitle={Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages={313--322},
	year={2015},
	organization={ACM}
}
Different CF-approaches (memory- and model-based) for binary data. Used k-nearest-neighbour notation from there.
Applied (numeric) SVD to item-item / user-user - score matrix instead of feedback matrix



===========================================================================
Collaborative filtering - Model-based
===========================================================================

@inproceedings{matrixFactorizationDifRegParam,
	title={Matrix factorization and neighbor based algorithms for the netflix prize problem},
	author={Tak{\'a}cs, G{\'a}bor and Pil{\'a}szy, Istv{\'a}n and N{\'e}meth, Botty{\'a}n and Tikk, Domonkos},
	booktitle={Proceedings of the 2008 ACM conference on Recommender systems},
	pages={267--274},
	year={2008},
	organization={ACM}
}
Matrix factorization using different regularization parameters for p and q

@inproceedings{SVDNeuralNet,
	title={Learning Collaborative Information Filters.},
	author={Billsus, Daniel and Pazzani, Michael J},
	booktitle={Icml},
	volume={98},
	pages={46--54},
	year={1998}
}
SVD and neural network applied to rating data to overcome cf shortcomings

@misc{funkLeastSquares,
	title = {Netflix Update: Try This at Home},
	howpublished = {\url{http://sifter.org/~simon/journal/20061211.html}},
	note = {Accessed: 2017-01-24}
}
Optimization for SVD approach (different from mine).

===========================================================================
SVD
===========================================================================

@inbook{svdGolubGeneral,
	title={Matrix computations. third},
	author={Golub, Gene H and Van Loan, Charles F},
	chapter = {2},
	year={1996},
	publisher={The John Hopkins University Press}
}
SVD basics (general features and such, no computation/algorithms)


@article{svdGolubSolution,
	title={Singular value decomposition and least squares solutions},
	author={Golub, Gene H and Reinsch, Christian},
	journal={Numerische mathematik},
	volume={14},
	number={5},
	pages={403--420},
	year={1970},
	publisher={Springer}
}
SVD algorithm



===========================================================================
Dimensionality reduction
===========================================================================

@techreport{nnOnSvd,
	title={Application of dimensionality reduction in recommender system-a case study},
	author={Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John},
	year={2000},
	institution={DTIC Document}
}
Neighbour-based methods applied on decomposed matrix


@article{ngRegressionLectureNotes,
	title={CS229 Lecture notes},
	author={Ng, Andrew},
	journal={CS229 Lecture notes},
	year={2000}
}
Andrew Ng lecture notes about linear regression

===========================================================================
Implicit feedback, one-class recommendation, ranking problematic
===========================================================================

@inproceedings{occf,
	title={One-class collaborative filtering},
	author={Pan, Rong and Zhou, Yunhong and Cao, Bin and Liu, Nathan N and Lukose, Rajan and Scholz, Martin and Yang, Qiang},
	booktitle={2008 Eighth IEEE International Conference on Data Mining},
	pages={502--511},
	year={2008},
	organization={IEEE}
}
Weighting and sampling schemes for one-class collaborative filtering


@inproceedings{CFForImplFeedback,
	title={Collaborative filtering for implicit feedback datasets},
	author={Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
	booktitle={2008 Eighth IEEE International Conference on Data Mining},
	pages={263--272},
	year={2008},
	organization={Ieee}
}
Incorporating confidence into user feedback

@inproceedings{implExplComparisonLastfm,
	title={Comparison of implicit and explicit feedback from an online music recommendation service},
	author={Jawaheer, Gawesh and Szomszor, Martin and Kostkova, Patty},
	booktitle={proceedings of the 1st international workshop on information heterogeneity and fusion in recommender systems},
	pages={47--51},
	year={2010},
	organization={ACM}
}
Comparison of implict and explicit feedback on last.fm data

===========================================================================
Boosting
===========================================================================
@article{boostingIntro,
	title={A short introduction to boosting},
	author={Freund, Yoav and Schapire, Robert and Abe, N},
	journal={Journal-Japanese Society For Artificial Intelligence},
	volume={14},
	number={771-780},
	pages={1612},
	year={1999},
	publisher={JAPANESE SOC ARTIFICIAL INTELL}
}


@article{boostingCFRatings,
	title={Novel Boosting Frameworks to Improve the Performance of Collaborative Filtering.},
	author={Jiang, Xiaotian and Niu, Zhendong and Guo, Jiamin and Mustafa, Ghulam and Lin, Zi-Han and Chen, Baomi and Zhou, Qian},
	journal={ACML},
	volume={13},
	pages={87--99},
	year={2013}
}
Boosting on predicting ratings

@article{boostingSchapire,
	title={The strength of weak learnability},
	author={Schapire, Robert E},
	journal={Machine learning},
	volume={5},
	number={2},
	pages={197--227},
	year={1990},
	publisher={Springer}
}
Scharpire 1st boosting

@inproceedings{boostingFreund,
	title={Boosting a Weak Learning Algorithm by Majority.},
	author={Freund, Yoav},
	booktitle={COLT},
	volume={90},
	pages={202--216},
	year={1990}
}
Freund Boosting

@inproceedings{resamplingReweighting,
	title={Resampling or reweighting: a comparison of boosting implementations},
	author={Seiffert, Chris and Khoshgoftaar, Taghi M and Van Hulse, Jason and Napolitano, Amri},
	booktitle={2008 20th IEEE International Conference on Tools with Artificial Intelligence},
	volume={1},
	pages={445--451},
	year={2008},
	organization={IEEE}
}
Comparison of resampling and reweighting techniques in boosting


@inproceedings{boostingAUC,
	title={A boosting algorithm for item recommendation with implicit feedback},
	author={Liu, Yong and Zhao, Peilin and Sun, Aixin and Miao, Chunyan},
	booktitle={IJCAI},
	volume={15},
	pages={1792--1798},
	year={2015}
}
Application of boosting optimizing MAP or AUC value


===========================================================================
Content-based
============================================================

@incollection{contentbasedPazzani,
	title={Content-based recommendation systems},
	author={Pazzani, Michael J and Billsus, Daniel},
	booktitle={The adaptive web},
	pages={325--341},
	year={2007},
	publisher={Springer}
}
Some content-based techniques, among others Bayes and nearest neighbours

===========================================================================
Hybrid systems
===========================================================================

@incollection{hybridSurvey,
	title={Hybrid web recommender systems},
	author={Burke, Robin},
	booktitle={The adaptive web},
	pages={377--408},
	year={2007},
	publisher={Springer}
}
Survey of different hybrids for restaurant recommender (knowledge-based)

@inproceedings{hybridcfcbClaypool,
	title={Combining content-based and collaborative filters in an online newspaper},
	author={Claypool, Mark and Gokhale, Anuja and Miranda, Tim and Murnikov, Pavel and Netes, Dmitry and Sartin, Matthew},
	booktitle={Proceedings of ACM SIGIR workshop on recommender systems},
	volume={60},
	year={1999},
	organization={Citeseer}
}
Weighted hybrid of user-based CF and content-based filter for news articles

@inproceedings{hybridCFCBClustringLi,
	title={An approach for combining content-based and collaborative filters},
	author={Li, Qing and Kim, Byeong Man},
	booktitle={Proceedings of the sixth international workshop on Information retrieval with Asian languages-Volume 11},
	pages={17--24},
	year={2003},
	organization={Association for Computational Linguistics}
}
Hybrid by clustering items (or users) using cb features and apply neighbour-based cf to the new matrix.

===========================================================================
Vertx
===========================================================================

@misc{vertx,
	title = {Vert.x},
	howpublished = {\url{http://http://vertx.io/}},
	note = {Accessed: 2017-01-15}
}
