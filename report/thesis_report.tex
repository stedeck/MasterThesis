\documentclass[10pt]{reportMaster}

\title{Recommender system for multiple online shops}
\author{S.\ Deckers}
\id{} %TODO find out title
\department{Artificial Intelligence}
\committee{Dr. K. Driessens \\ Dr. J. Derks}
\date{} %TODO fill in date of submission


% new line instead of indent for new paragraph
\usepackage[parfill]{parskip}
\usepackage{ dsfont }

\begin{document}
\maketitle

%==============================================================
\chapter{Introduction}
%TODO write introduction
Recommendation systems are systems that aim to make personalized content recommendations to its users.
They are widely used in the world wide web in different contexts such as movie recommendation in the streaming service Netflix or music recommendation as in last.fm as well as in e-commerce to recommend products that the user might purchase.
They seek to provide users with items that are new to them or they might not have discovered otherwise.

While in the context of Netflix or last.fm the users actively search for new movies or music and intentionally use the recommendation system, in the context of e-commerce recommendations are usually shown while browsing the website.
This also reflects in the kind of input the users give to the recommendation system.
In systems like Netflix and last.fm the users give explicit feedback to different items in the form of ratings to express how much a user likes an item or by simply stating whether the user likes or dislikes an item.
E-commerce services in contrast need to derive user preferences from their purchase or browsing behaviour.
This kind of feedback is called implicit feedback.

Moreover the available datasets vary in number of users, number of items and amount of sparseness.
The success of a specific recommendation technique depends on the available data.
So for a specific dataset a suitable recommendation algorithm need to be found. %TODO find reference to prove that different datasets need different techniques
In this thesis different algorithms will be investigated to find a suitable technique for product recommendation in e-commerce.
%TODO find a dataset with more items than users (I think in handbook was news dataset was mentioned)
%TODO add reference to further chapter where I will explain in more detail which techniques work well for which datasets

A general challenge for recommendation is the high dimensionality and sparseness of the data.
Usually there is a high amount of users and items, but a single user only interacts with a relatively small amount of items and many items are only considered by a small amount of users.
% TODO how is this relevant for my thesis? fast recommendation are more difficult



%todo eventually add more details about implicit feedback 
%todo could add that there are interactive systems or configarionable ones
%todo also could add different requirements from the handbook


\section{Problem statement}
%TODO write problem statment section
What is my specific task?
my recommender system should serve different online shops / should work for different data
since different techniques perform different on different datasets I first need to investigate which techniques to use.
so first find how single recommenders perform and how they can be combined
I need the recommender system to automatically tune for different datasets.
general description of data (binary, implicit, sparse, purchases, views, shop cart entries, ...)

\section{Contribution}
%TODO write contribution section
What is novel in my thesis?
What is the specific challenge? (e-commerce seems to have different requirements (sarwar has different results for e-commerce and movielens data), implicit/binary data, no negative preferences, should work for multiple sets)

\section{Related work}
%TODO write related work section
Who did similar work?
What results did they observe?










%==============================================================
\chapter{Recommender Systems}
There are different types of recommendation systems.
They can be divided into collaborative filtering (CF), content-based (CB), demographic, knowledge-based or network-based recommenders. % TODO add reference
The most important ones are collaborative filtering and content-based recommenders.% TODO why are they most important
These techniques are applied for the recommendation system developed in the scope of this thesis and will be addressed in the next two sections.
In section \ref{rs_others} the other mentioned techniques will be shortly introduced to complete the picture of possible recommendation techniques.

\section{Collaborative filtering}
\label{rs_cf}
%TODO write CF chapter
Collaborative filtering is the most implemented and successful recommendation technique. %TODO add reference
Recommendations are made based on the preferences of all users using their ratings in the context of netflix or their purchases in an e-commerce context.
These information is represented as a matrix where users a represented as rows and columns represent the items.
Every matrix entry indicates the interaction of a specific user-item pair.
For e-commerce data there is an entry of 1 indicating preference for every item a user purchased.
The other entries remain empty or zero indicating that preference for these items are unknown. %TODO maybe write an own chapter for data representation and put this there

Collaborative filtering techniques are divided again into two different approaches: memory-based and model-based approaches.
While memory-based approaches directly make use of the preference matrix, model-based approaches train an alternative model and use this model to make recommendations.
Model-based recommendation systems need some time to train the model, but are able to make faster recommendations, because the full purchase matrix does not need to be taken into account, but the more compact model can be used.
Moreover model-based techniques usually need less memory, because the full purchase matrix is not needed.

In this thesis two memory-based and one model-based approach was investigated.
The memory-based techniques are k-nearest-neighbour algorithms applied on the purchase matrix.
They either take the similarities between users or items into account. % TODO add references to other papers that use item-item approach
In the item-item approach those items are recommended that are closest to the items the current user has already purchased.
For every item $i$ the current user $u$ has not purchased a score is calculated by $S(u,i) = \sum_{j \in I(u)}{sim(R(:,i), R(:,j))}$. Here $R \in \mathds{R}^{n \times m}$ denotes the purchase matrix for $n$ users and $m$ items. $R(:,i)$ denotes the $i^{th}$ column vector. $I(u)$ is the set of items user u purchased.
Then those items are purchased that reach the highest score. %TODO add pseudocode algorithm
The function $sim(R(:,i), R(:,j))$ can be substituted by any vector similarity function.
In this thesis experiments were performed using cosine similarity or the Jaccard coefficient explained in section . %TODO write section and reference to it

The second memory-based algorithm is a user-user similarity approach.
Here the similarities between users is taken into account instead of item similarities.
In the first step the nearest neighbours of the current user $u$ are determined by getting those users $v$ which reach the highest score according to $S(u,v) = sim(R(u,:)^T, R(v, :)^T)$.
$R(u,:)$ and $R(v,:)$ are the $u^{th}$ and $v^{th}$ row vectors of the purchase matrix, respectively.
The similarity function $sim(R(u,:)^T, R(v, :)^T)$ refers to the same vector similarities as in the item-item approach, see . %TODO add reference
After the nearest neighbours of user $u$ are obtained, those items are recommended that are purchased most often by the determined neighbours. %TODO add pseudo code algorithm

%TODO explain problems and my solutions:
%TODO the neighbors may not have purchased enough items (either in general or additionaly to the items u already purchased). to reduce the risk a did not neighbors to the list that have a similarity of one, because a similarty of 1 means that the two users have purchased exactly the same set of items

%TODO advantaged and drawbacks of those 
%TODO what are actual differences?
%TODO find paper where those are applied or at least similiary applied and how mine version is different

%Explain general svd %TODO add references
The most common model-based collaborative filtering approach works by matrix factorization like singular value decomposition (SVD).
It is aimed to find latent factor features to represent users and items instead of using the whole vectors from the purchase matrix.
Generally SVD decomposes a matrix $A \in \mathds{R}^{m \times n}$ into the matrices $U \in \mathds{R}^{n \times f}$, $\Sigma \in \mathds{R}^{f \times f}$ and $V \in \mathds{R}^{m \times f}$, such that $A = U \Sigma V^T$.
The column vectors of $U$ are the eigenvectors of $A^TA$, the columns of $V$ are the eigenvectors of $AA^T$. %TODO or was it the other way around?
$\Sigma$ is a diagonal matrix containing the corresponding eigenvalues. %TODO or the squares or root of eigenvalues? %TODO explain relation to pca
The eigenvectors in $U$ and $V$ and their corresponding eigenvalues in $\Sigma$ are sorted in descending order.
%TODO fix... n times f and so on is already reduced. explain how the dimension are before and how they can be reduced and that this is low rank approximation. explain how this is related to the feature matrix and how the resulting matrices can be interpreted. introduce matrices P and Q for user and item 

%Explain linear regression approach commonly used for recommendation
For recommendation systems the reduced user and item representations are often trained by linear regression instead of applying a numerical method to decompose a rating matrix.
For every user $u$ a feature vector $p_u \in \mathds{R}^f$ and for every item $i$ a feature vector $q_i \in \mathds{R}^f$ is trained by optimizing $r_{u,i} = $. %TODO add function and continue explaining alternating least squares, what are the actual updates, what about regulization, ...


%describe problems for implicit / binary feedback

%Explain my adaption to logistic regression

%Explain possibilities of how to handle missing / zero values

%summarize my version of the algorithm including pseudo code algorithm


%TODO eventually add other approaches of sampling i have tried
%TODO describe svd in general
%TODO why do usual approaches not work on implicit feedback
%TODO mention svd on implicit feedback papers and why they are not applicable
%TODO what are my solutions for the problems (reference to boosting chapter)

\section{Content-based recommendation systems} %TODO see how content-based is written
\label{rs_cb}
%TODO write contentbased section
Another common approach is content-based filtering.
This approach generates recommendations from any kind of content-based item features independently from other users' preferences.
The item features may be information about genres, actors or directors in a movie recommendation context.
For the dataset used in this thesis there are categories and description texts about the items.
An item can be in multiple categories, so they are represented as vectors $\vec{x} \in \mathds{R}^{|C|}$ where $|C|$ is the number of available categories.
The vector elements $x_c \in \{0,1\}$ indicate whether the item belongs to a specific category or not. 
Texts are represented as word vectors $\vec{x} \in \mathds{R}^{|T|}$ with $T$ being the total number of words in any of the item descriptions.
The vector elements $x_i$ are either binary values indicating the occurrence or absence of a word in the text, the number of occurrences of a word (bag-of-word model) or the corresponding tf-idf value. %TODO explain tf-idf and the formula I used

% What algorithms can be applied? explain naive bayes (because it seems to be often used) and nearest neighbor (because of simplicity)
The general idea is to recommend items that are most similar to the items the user has already purchased with respect to the given content-based features.
Two algorithms have been implemented: Naive Bayes classification and k-nearest-neighbour. % TODO add bayes references
Naive Bayes determines the probability that a user purchases a specific item based on the likelihood of its single features.
For every user a profile is trained consisting of the %TODO explain Bayes

The second algorithm is another k-nearest-neighbour implementation similar to item-item approach explained in section \ref{rs_cf}.
This is the same implementation as in the collaborative filtering recommendation system, but instead of the column vectors of the purchase matrix the category or text feature vectors are used.
In the case of bag-of-words or tf-idf representation of items the cosine-similarity is used.
For the binary text or category representation either cosine similarity or the Jaccard coefficient can be used.

% add pseudo code algorihtms for both approaches

% explain problems (better in discussion section i guess, same for problems in other approaches above): too similar items, bayes takes to long. why?

% explain possible solutions for problems: eventually combine with other recommenders



 
\section{Other recommendation systems}
\label{rs_others}
%TODO write other rs section
% demographic and network recommenders.
Besides collaborative filtering and content-based recommendation there are other recommendation systems like knowledge-based, demographic or network recommendation systems.
Knowledge-based recommender systems 









%==============================================================
\chapter{AdaBoost for recommendation systems}
\section{Boosting}
%TODO plan and continue











%==============================================================
\chapter{Hybrid recommendations systems}
%TODO write introduction for hybrid rs

\section{Switching hybrid}
%TODO write switching hybrid section

\section{Weighted hybrid}
%TODO write weighted hybrid section

\section{Cascade hybrid}
%TODO write cascade hybrid section

\section{Other hybrids}
%TODO write other hybrids section
shorty describe other hybrid sections from burke and why are they not used in this thesis







%==============================================================
\chapter{Adaptive hybridization}
%TODO write adaptive hybrid introduction

\section{Adaptive switching hybrid}
%TODO write adpative switching section


\section{Adaptive weighted hybrid}
%TODO write adaptive weighted hybrid







%==============================================================
\chapter{Alternative models}
%TODO write alternative models chapte intoductions

\section{Incorporating browsing behaviour}
%TODO write browsing behavior chapter






%==============================================================
\chapter{Implementation and Performance}
%TODO write implementation and performance chapter introduction

\section{Reactive design}
%TODO write reactive design section

\section{Implementation of purchase matrix}
%TODO write purchase matrix implementation section

\section{High level architecture}
%TODO write high level architecture section

%TODO maybe add results for different matrix implementations







%==============================================================
\chapter{Experiments}
%TODO write experiments chapter introduction

\section{Data}
%TODO write data section

\section{Single recommendation systems}
%TODO write single rs experiment section

\section{Hybrid recommendation systems}
%TODO write hybrid rs experiment section

\section{Adaptive hybridization}
%TODO write adaptive hybrid experiment section

\section{Alternative models}
%TODO write alternative models experiment section







%==============================================================
\chapter{Results}
%TODO write results chapter introction

\section{Single recommendation systems}
%TODO write single rs result section

\section{Hybrid recommendation systems}
%TODO write hybrid rs result section

\section{Adaptive hybridization}
%TODO write adaptive hybrid result section

\section{Alternative models}
%TODO write alternative models result section







%==============================================================
\chapter{Discussion}
%TODO write discussion chapter introduction

\section{Single recommendation systems}
%TODO write single rs discussion section

\section{Hybrid recommendation systems}
%TODO write hybrid rs discussion section

\section{Adaptive hybridization}
%TODO write adaptive hybrid discussion section

\section{Alternative models}
%TODO write alternative models discussion section







%==============================================================
\chapter{Conclusion and Future Work}









\bibliography{thesis_report}
\bibliographystyle{unsrt}
\end{document}

